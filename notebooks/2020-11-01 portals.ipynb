{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Portal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pyspark.sql import SparkSession, functions as F, types as T, Window\n",
    "\n",
    "\n",
    "def flatten(df, path: list, dtype: str):\n",
    "    \"\"\"Flatten a document based on a path.\"\"\"\n",
    "    if len(path) < 2:\n",
    "        raise ValueError(\"path must be at least two elements long\")\n",
    "    sub = df\n",
    "    # walk the tree\n",
    "    for i in range(len(path) - 1):\n",
    "        key = path[i]\n",
    "        subkey = path[i + 1]\n",
    "        # TODO: test nested 3 deep\n",
    "        next_dtype = \"imgdir\" if i < len(path) else dtype\n",
    "        sub = (\n",
    "            sub.select(F.col(\"_name\").alias(key), F.explode(\"imgdir\").alias(\"_tmp\"))\n",
    "            .select(*path[: i + 1], \"_tmp.*\")\n",
    "            .withColumn(subkey, F.col(\"_name\"))\n",
    "            .where(F.col(subkey) == subkey)\n",
    "            .drop(\"_name\", \"_value_tag\")\n",
    "        )\n",
    "        sub = sub.select(*(path[: i + 2] + [c for c in sub.columns if c not in path]))\n",
    "    if dtype == \"imgdir\":\n",
    "        return sub.select(*path, dtype)\n",
    "    is_array = sub.schema[dtype].dataType.typeName() == \"array\"\n",
    "    subdoc = sub.withColumn(\"_tmp\", F.explode(dtype) if is_array else F.col(dtype))\n",
    "    return (\n",
    "        subdoc.select(*path, \"_tmp.*\").groupBy(key).pivot(\"_name\").agg(F.max(\"_value\"))\n",
    "    )\n",
    "\n",
    "\n",
    "def get_portals(df):\n",
    "    k = [\"root\", \"portal\"]\n",
    "    q = (\n",
    "        flatten(df, k, \"imgdir\")\n",
    "        .select(*k, F.explode(\"imgdir\").alias(\"_tmp\"))\n",
    "        .select(*k, F.col(\"_tmp._name\").alias(\"i\"), \"_tmp.*\")\n",
    "        .drop(\"_name\", \"_value_tag\")\n",
    "        .select(*k, \"i\", F.explode(\"int\").alias(\"_tmp\"))\n",
    "        .where(F.col(\"_tmp._name\") == \"tm\")\n",
    "        # what is tm?\n",
    "        .select(\n",
    "            *k,\n",
    "            F.collect_list(\"_tmp._value\")\n",
    "            .over(Window.partitionBy(*k).orderBy(\"i\"))\n",
    "            .alias(\"tm\"),\n",
    "        )\n",
    "        .groupby(*k)\n",
    "        .agg(F.max(\"tm\").alias(\"tm\"))\n",
    "        .select(F.split(F.col(\"root\"), \"\\.\")[0].alias(\"src\").astype(\"int\"), F.col(\"tm\").alias(\"dst\"))\n",
    "    )\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wzpath = \"../../wzexports\"\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = (\n",
    "    spark.read.format(\"xml\")\n",
    "    .options(rowTag=\"imgdir\", valueTag=\"_value_tag\")\n",
    "    .load(f\"{wzpath}/Map.wz/Map/*/*.xml\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "portals = (\n",
    "    get_portals(df)\n",
    "    .select(\"src\", F.explode(\"dst\").alias(\"dst\"))\n",
    "    .groupBy(\"src\", \"dst\")\n",
    "    .agg(F.count(\"*\").alias(\"weight\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------+\n",
      "|      src|      dst|weight|\n",
      "+---------+---------+------+\n",
      "|    40000|    40001|     1|\n",
      "|100040003|999999999|     3|\n",
      "|101000003|999999999|     8|\n",
      "|101000200|101000200|     6|\n",
      "|101030102|101030101|     1|\n",
      "+---------+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "portals.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "portals.drop(\"weight\").where(\n",
    "    \"src <> 999999999 and dst <> 999999999\"\n",
    ").toPandas().to_csv(\"../data/processed/maps.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get string data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read.format(\"xml\")\n",
    "    .options(rowTag=\"imgdir\", valueTag=\"_value_tag\")\n",
    "    .load(f\"{wzpath}/String.wz/Map.img.xml\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----+-------+--------------------+-------------+\n",
      "|      uid|help0|help1|mapDesc|             mapName|   streetName|\n",
      "+---------+-----+-----+-------+--------------------+-------------+\n",
      "|100000004| null| null|   null|         Pig Park II|Hidden Street|\n",
      "|100000102| null| null|   null|Henesys Departmen...|Victoria Road|\n",
      "|100000116| null| null|   null|Henesys Free Mark...|Victoria Road|\n",
      "+---------+-----+-----+-------+--------------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- uid: long (nullable = true)\n",
      " |-- help0: string (nullable = true)\n",
      " |-- help1: string (nullable = true)\n",
      " |-- mapDesc: string (nullable = true)\n",
      " |-- mapName: string (nullable = true)\n",
      " |-- streetName: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def flat_region(df, region):\n",
    "    q=(\n",
    "        flatten(df, [\"root\", region], \"imgdir\")\n",
    "        .select(F.explode(\"imgdir\"))\n",
    "        .selectExpr(\"col._name as uid\", \"explode(col.string)\")\n",
    "        .groupBy(\"uid\")\n",
    "        .pivot(\"col._name\")\n",
    "        .agg(F.max(\"col._value\"))\n",
    "    )\n",
    "    return q\n",
    "\n",
    "q = flat_region(df, \"victoria\")\n",
    "q.cache()\n",
    "q.show(n=3, truncate=20)\n",
    "q.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.selectExpr(\"uid as Id\", \"mapName as Label\", \"streetName\").toPandas().to_csv(\n",
    "    \"../data/processed/victoriaLabels.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    portals.join(q.selectExpr(\"uid as src\"), how=\"inner\", on=\"src\")\n",
    "    .join(q.selectExpr(\"uid as dst\"), how=\"inner\", on=\"dst\")\n",
    "    .drop(\"weight\")\n",
    "    .toPandas()\n",
    "    .to_csv(\"../data/processed/victoria.csv\", index=False, header=False)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
